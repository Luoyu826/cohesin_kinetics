{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2407ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'harvey_plotting_v53'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shortest_path\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# import plotting functions\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mharvey_plotting_v53\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# import loop extrusion codes\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyximport\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'harvey_plotting_v53'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "# for parallel processing\n",
    "from multiprocess import Pool\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "# import plotting functions\n",
    "from harvey_plotting_v53 import *\n",
    "\n",
    "# import loop extrusion codes\n",
    "import pyximport\n",
    "pyximport.install(setup_args={'include_dirs':np.get_include()})\n",
    "from loop_extrusion_twoLEFpopulations_CollidingSuperExtruder_SuperLoading_v15 import LEFTranslocatorDirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72527d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill>=0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: dill, multiprocess\n",
      "Successfully installed dill-0.3.6 multiprocess-0.70.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install multiprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6bc48",
   "metadata": {},
   "source": [
    "# Set up chromosome and get all boundary element coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output folder \n",
    "output_folder = 'output_1013_test_run1'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "tiling_factor = 600 # number of TAD arrays repeated\n",
    "\n",
    "# set up boundary elements\n",
    "boundary_coordinates = [0, 200,201, 601,602, 802,803, 1603,1604, 1804,1805, 2205,2206, 2406,2407, 3607] # coordinates of boundary elements\n",
    "TAD_array_size =  boundary_coordinates[-1] + 1 # the size of the big TAD in kb\n",
    "chrom_size = TAD_array_size*tiling_factor # the total size of the chromosome in kb\n",
    "boundary_coordinates_o = boundary_coordinates # coordinates of boundary elements within the first TAD array\n",
    "\n",
    "# obtain the coordinates of all boundary elements and the double strand break sites on the chromosome\n",
    "for j in range(tiling_factor-1):\n",
    "    k = TAD_array_size*(j+1)\n",
    "    res = [x + k for x in boundary_coordinates_o] \n",
    "    boundary_coordinates = boundary_coordinates + res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d9b26",
   "metadata": {},
   "source": [
    "# DSB coordiantes set up, no need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6709ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly determine the coordinate of the DSB in the first TAD\n",
    "random_pick_0 = int(np.random.random()*(boundary_coordinates_o[1]-boundary_coordinates_o[0]-2)+boundary_coordinates_o[0]+1)\n",
    "if random_pick_0+1 == boundary_coordinates[1]:\n",
    "    DSB_coordinates = [random_pick_0-1, random_pick_0]\n",
    "else:\n",
    "    DSB_coordinates = [random_pick_0, random_pick_0+1]\n",
    "\n",
    "# counters for the number of subTADs with a double strand break\n",
    "tad_200 = 1 \n",
    "tad_400 = 0\n",
    "tad_800 = 0\n",
    "tad_1200 = 0\n",
    "tad_count = np.asarray([1,0,0,0]) # counter for TAD of each size containing DSB\n",
    "tad_size = np.asarray([200, 400, 800, 1200]) dist_between_break = 10000 #kb distances between two DSB\n",
    "\n",
    "DSB_dist_to_CTCF = [min(DSB_coordinates[0]-boundary_coordinates[0],boundary_coordinates[1]-DSB_coordinates[0])] \n",
    "\n",
    "DSB_TAD_array_size = [200]\n",
    "within_tile = True\n",
    "while within_tile:\n",
    "    # skip dist_between_break \n",
    "    next_break = DSB_coordinates[-1] + dist_between_break\n",
    "    # preventing the next DSB occurring at a boundary element\n",
    "    if np.count_nonzero(next_break - np.asarray(boundary_coordinates))<len(boundary_coordinates):\n",
    "        next_break += 2\n",
    "    # determine the TAD the next DSB occurs in\n",
    "    test = np.asarray(boundary_coordinates) - next_break\n",
    "    boundray_index = np.argmax(test>0) # the first BE coordinates to the right of the DSB\n",
    "    # randomize the coordinate of the DSB within the TAD (so that the distance between DSB and BE is randomized)\n",
    "    random_pick = int(np.random.random()*(boundary_coordinates[boundray_index]-boundary_coordinates[boundray_index-1]-2)+boundary_coordinates[boundray_index-1]+1)\n",
    "    if random_pick+1 == boundary_coordinates[boundray_index]:\n",
    "        DSB_coordinates += [random_pick-1, random_pick]\n",
    "    else:\n",
    "        DSB_coordinates += [random_pick, random_pick+1]\n",
    "    tad_size_index = np.argwhere(tad_size==boundary_coordinates[boundray_index]-boundary_coordinates[boundray_index-1])[0][0]\n",
    "    tad_count[tad_size_index]+=1\n",
    "    DSB_TAD_array_size.append(tad_size[tad_size_index])\n",
    "    if DSB_coordinates[-1] + dist_between_break> chrom_size-1:\n",
    "        within_tile = False\n",
    "\n",
    "\n",
    "DSB_TAD_array_size = np.asarray(DSB_TAD_array_size)\n",
    "        \n",
    "LogFileName = output_folder+\"/log.txt\"\n",
    "\n",
    "o = open(LogFileName, \"w\") \n",
    "o.close()\n",
    "\n",
    "with open(LogFileName, \"a\") as f:\n",
    "    f.write('Tiling factor: \\n')\n",
    "    f.write(str(tiling_factor)+'\\n')\n",
    "    for i in range(len(tad_size)):\n",
    "        f.write('number of breaks within a '+str(tad_size[i])+'kb TADs: \\n')\n",
    "        f.write(str(tad_count[i])+'\\n')\n",
    "\n",
    "file = output_folder+'/DSB_boundary_coordinates.npy' \n",
    "\n",
    "# saving DSB coordinates and boundary coordinates to robustness \n",
    "if not os.path.exists(file):\n",
    "    with open(file, 'wb') as g:\n",
    "        np.save(g, np.asarray(DSB_coordinates))\n",
    "        np.save(g, np.asarray(boundary_coordinates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631dad74",
   "metadata": {},
   "source": [
    "# sweep parameters (from Fbn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763ebfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define simulation parameters\n",
    "# list of (separation,processivity) tuple \n",
    "sep_proc_list = []\n",
    "sep_list = [125]\n",
    "proc_list = [250]\n",
    "for sep in sep_list:\n",
    "    for proc in proc_list:\n",
    "        sep_proc_list.append((sep,proc))\n",
    "        \n",
    "proc_ratio = 20 # the ratio of long-lived LEF processivity over normal LEF processivity  \n",
    "BE_stabilization_factor_list =  [16] # the fold stabilization of LEF at BE\n",
    "DSB_stabilization_factor_list = [4] # the fold stabilization of LEF at DSB ends\n",
    "boundary_strength_list = [0.5] # the probability of LEF stalled by an boundary element\n",
    "longlived_fraction_list = [0.2] # percentage of long-lived LEFs in the total LEF polulation\n",
    "targetedloading_factor_list = [1000] # fold increase of loading probability at the DSB ends\n",
    "\n",
    "alpha_list = [1, 3, 5]   # threshold distance: half of the unfilled gap size (in kb) for calling synapsis\n",
    "\n",
    "# other input parameters\n",
    "LEF_step_probability = 1 # the probability LEF taking a step\n",
    "    \n",
    "# maximum number of steps post DSB to stop simulation\n",
    "step_count_limit = 40000\n",
    "\n",
    "# whether to take snapshots of the synapsis process\n",
    "plot_snapshots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc802fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_parameter_set(sep_proc_pair, boundary_strength, BEstabilization_factor, \n",
    "                         DSBstabilization_factor,longlived_fraction, super_loading_factor, \n",
    "                         proc_ratio,chrom_size, step_count_limit,alpha_list,boundary_coordinates,DSB_coordinates,\n",
    "                         LEF_step_probability,DSB_TAD_array_size, plot_snapshots = False):\n",
    "    \n",
    "    # assume uniform loading probability on the whole chromosome\n",
    "    loading_prob = np.ones(chrom_size)/chrom_size # the probability LEF loads at each lattice site on the chromosome\n",
    "    stall_prob_left = np.zeros(chrom_size, dtype=np.double) # numpy array to store the probability of left motor subunits of LEFs being stalled\n",
    "    stall_prob_right = np.zeros(chrom_size, dtype=np.double) # numpy array to store the probability of right motor subunits of LEFs being stalled\n",
    "    \n",
    "    separations = sep_proc_pair[0]\n",
    "    processivity = sep_proc_pair[1]\n",
    "    processivity_longlived = processivity * proc_ratio #processivity of long-lived LEFs\n",
    "    \n",
    "    # if boundary_strength is 0, there is no stabilization of LEF at BE\n",
    "    BEstabilization_factor_o = BEstabilization_factor \n",
    "    if boundary_strength == 0:\n",
    "        BEstabilization_factor = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
